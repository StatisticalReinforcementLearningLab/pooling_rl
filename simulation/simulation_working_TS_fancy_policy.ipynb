{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import sim_functions as sf\n",
    "import sys\n",
    "sys.path\n",
    "sys.path.append('../models')\n",
    "import state_params\n",
    "from numpy.random import uniform\n",
    "import TS_fancy\n",
    "import eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Context: \n",
    "group_id,day_of_week,time_of_day,location,weather,previous_step_count,last_step_count,variation_in_step_counts\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A study needs some days. So you can specify days like this: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days = pd.date_range(start = '7/22/2015',end =pd.Timestamp('7/22/2015')+pd.DateOffset(days=90),freq='30T')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made 90 days because that's  the length of the study\n",
    "However, because I am lazy, I'm only testing for a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-07-22 00:00:00', '2015-07-22 00:30:00',\n",
       "               '2015-07-22 01:00:00', '2015-07-22 01:30:00',\n",
       "               '2015-07-22 02:00:00', '2015-07-22 02:30:00',\n",
       "               '2015-07-22 03:00:00', '2015-07-22 03:30:00',\n",
       "               '2015-07-22 04:00:00', '2015-07-22 04:30:00',\n",
       "               ...\n",
       "               '2015-07-25 07:00:00', '2015-07-25 07:30:00',\n",
       "               '2015-07-25 08:00:00', '2015-07-25 08:30:00',\n",
       "               '2015-07-25 09:00:00', '2015-07-25 09:30:00',\n",
       "               '2015-07-25 10:00:00', '2015-07-25 10:30:00',\n",
       "               '2015-07-25 11:00:00', '2015-07-25 11:30:00'],\n",
       "              dtype='datetime64[ns]', length=168, freq='30T')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_indices = days[:24*7]\n",
    "temp_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass in a bunch of decision times. I just tested with one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decision_times = pd.DatetimeIndex(['2015-07-25 11:00:00'])\n",
    "num_people = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now I think the number of people is being totally ignored. This needs to be fixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_initial_context(num_people,first_index):\n",
    "    return sf.get_initial_context(num_people,first_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peoples_context = get_initial_context(num_people,temp_indices[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(peoples_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simulate_run(num_people,time_indices,decision_times,init=None,action_algorithm = None):\n",
    "    \n",
    "    \n",
    "    initial_contexts = sf.get_initial_context(num_people,time_indices[0])\n",
    "    \n",
    "    ##for now number of people is one\n",
    "    \n",
    "    all_people = []\n",
    "    \n",
    "    \n",
    "                 \n",
    "    ##Initialize bandit algorithm\n",
    "    \n",
    "    \n",
    "    all_rewards = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##Time is constrained by the input times\n",
    "\n",
    "    \n",
    "    \n",
    "    for n in range(num_people):\n",
    "        #print('person')\n",
    "        initial_context = initial_contexts[n]\n",
    "    \n",
    "        total_reward = 0\n",
    "        \n",
    "        the_eta = eta.eta()\n",
    "    \n",
    "        current_eta = the_eta.eta_init\n",
    "        \n",
    "        batch = [[] for i in range(len(time_indices))]\n",
    "        \n",
    "        ##place_holder\n",
    "        Z_init = initial_context[:4]\n",
    "        ##these two should be in context vector\n",
    "        X_init = 0 \n",
    "        I_init = (uniform() < 0.8)\n",
    "        \n",
    "         # policy initilization\n",
    "        mu_beta = init.mu_2\n",
    "        Sigma_beta = init.sigma_2\n",
    "        \n",
    "        initial_steps = sf.get_steps(initial_context,-1)\n",
    "        current_steps = initial_steps\n",
    "        action = -1 \n",
    "        all_steps = []\n",
    "    \n",
    "        last_day = time_indices[0]\n",
    "    \n",
    "        new_day = False\n",
    "    \n",
    "        #for d in range(num_days):\n",
    "    \n",
    "    \n",
    "        start_of_day = 0 \n",
    "        end_of_day=0\n",
    "        current_index=0\n",
    "    \n",
    "    \n",
    "        first_week = time_indices[0].date()+pd.DateOffset(days=7)\n",
    "        batch_index = 0 \n",
    "        \n",
    "        dt_counter = 0 \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in time_indices:\n",
    "           \n",
    "            \n",
    "            ##Everything I do before I advance the day\n",
    "            \n",
    "            if i == time_indices[0]:\n",
    "      \n",
    "                Z_next = Z_init\n",
    "                X_next = X_init\n",
    "                I_next = I_init\n",
    "      \n",
    "    \n",
    "            Z = Z_next\n",
    "            X = X_next\n",
    "            I = I_next\n",
    "            \n",
    "            \n",
    "            if I==1:\n",
    "                prob = TS_fancy.prob_cal(Z, X, mu_beta, Sigma_beta, init,current_eta)\n",
    "                    # sample the action\n",
    "                A = int(uniform() < prob)\n",
    "                    \n",
    "            else:\n",
    "      \n",
    "                prob = 0\n",
    "                A = 0\n",
    "            \n",
    "            R = 1+Z[0]+(Z[0]**2)-(.05*X)+A*(1-.1*X)+np.random.normal(scale=1)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            if i.date()!=last_day.date():\n",
    "           \n",
    "                new_day=True\n",
    "            \n",
    "            \n",
    "            \n",
    "            decision_time = bool(i in decision_times)\n",
    "    \n",
    "            if i!=time_indices[0]:\n",
    "          \n",
    "                \n",
    "                if i in decision_times:\n",
    "                    \n",
    "                    if action_algorithm==None:\n",
    "                        action = sf.get_action(my_context,current_steps)\n",
    "                    elif action_algorithm=='TS_fancy':\n",
    "                        ##first get action, then update policy - so this weaving needs to be straight\n",
    "                        action=A\n",
    "                    else:\n",
    "                        action = -1\n",
    "                \n",
    "                    dt_counter = dt_counter+1\n",
    "           \n",
    "                lsc = initial_context[sf.get_index('yesterday')]\n",
    "                variation = initial_context[sf.get_index('variation')]\n",
    "                if new_day:\n",
    "\n",
    "                \n",
    "                \n",
    "        \n",
    "                    if i<first_week:\n",
    "                        variation = sf.get_variation_pre_week(variation,all_steps,time_indices,last_day)\n",
    "                    else:\n",
    "                        variation = sf.get_variation(all_steps,time_indices,last_day)\n",
    "                \n",
    "                \n",
    "                    lsc = sf.get_new_lsc(all_steps[start_of_day:end_of_day])\n",
    "           \n",
    "                \n",
    "            \n",
    "                #which context is this? - do i need both?\n",
    "                \n",
    "                \n",
    "                ##before getting action need to upate A and Prob\n",
    "\n",
    "            \n",
    "                ##fix this\n",
    "                ##is this always what the reward should be?\n",
    "                \n",
    "                Z_next = initial_context[:4]\n",
    "                X_next = TS_fancy.gen_nextdosage(X,A)\n",
    "                I_next = (uniform()<.8)\n",
    "        \n",
    "        \n",
    "               \n",
    "            \n",
    "\n",
    "            ##redo get_steps\n",
    "            \n",
    "                my_context = sf.get_context_revised(i,initial_context,current_steps,decision_time,lsc,variation,action)\n",
    "               \n",
    "                \n",
    "                next_steps = sf.get_steps(my_context,action) \n",
    "                all_steps.append(next_steps)\n",
    "                initial_context = my_context\n",
    "                current_steps = next_steps\n",
    "            else:\n",
    "                if i in decision_times:\n",
    "                    #print('type two decision time')\n",
    "                    if action_algorithm==None:\n",
    "                        action = sf.get_action(initial_context,current_steps)\n",
    "                    elif action_algorithm=='TS_fancy':\n",
    "                        ##first get action, then update policy - so this weaving needs to be straight\n",
    "                        action=A\n",
    "                    \n",
    "                else:\n",
    "                    action = -1\n",
    "                dt_counter = dt_counter+1\n",
    "                \n",
    "                next_steps = sf.get_steps(initial_context,action) \n",
    "                all_steps.append(next_steps)\n",
    "                current_steps = next_steps\n",
    "                \n",
    "                ##SET Z_next, X_next, I_next\n",
    "                \n",
    "                \n",
    "                \n",
    "            if new_day:\n",
    "            \n",
    "                start_of_day = current_index\n",
    "                new_day=False\n",
    "            \n",
    "            \n",
    "            batch[batch_index]=TS_fancy.make_batch(batch_index,Z,X,I,A,prob,R)\n",
    "        \n",
    "        \n",
    "            total_reward = total_reward+R\n",
    "            \n",
    "            last_day = i\n",
    "            end_of_day = current_index  \n",
    "            current_index = current_index+1\n",
    "           \n",
    "            total_reward = total_reward+R\n",
    "            \n",
    "            \n",
    "            ##this assumes we update the policy at the end\n",
    "            if i in decision_times and dt_counter==4:\n",
    "                temp = TS_fancy.policy_update_ts(batch[:batch_index], init)\n",
    "                        #print(temp)\n",
    "                mu_beta = temp[0]\n",
    "                Sigma_beta = temp[1]\n",
    "                eta_params = temp[2]\n",
    "                the_eta.update_params(eta_params)\n",
    "                current_eta = the_eta.eta_function\n",
    "                dt_counter = 0\n",
    "            batch_index = batch_index+1\n",
    "        all_people.append(all_steps)\n",
    "            \n",
    "    return all_people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp = state_params.state_params(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x=simulate_run(num_people,temp_indices,decision_times,init=sp,action_algorithm = 'TS_fancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "for i in range(5):\n",
    "    all_runs.append(simulate_run(num_people,temp_indices,decision_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
