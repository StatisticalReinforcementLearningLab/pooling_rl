{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path\n",
    "sys.path.append('../models')\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import sim_functions_cleaner  as sf\n",
    "import operator\n",
    "import study\n",
    "import time\n",
    "import TS_personal_params_pooled as pp\n",
    "import TS_global_params_pooled as gtp\n",
    "from numpy.random import uniform\n",
    "\n",
    "#sys.path.append('../simulation')\n",
    "import TS_fancy_pooled\n",
    "#import TS_fancy_pooled\n",
    "import eta\n",
    "import pooling_bandits as pb\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_policy_params_TS(experiment):\n",
    "    \n",
    "    global_p =gtp.TS_global_params(10)\n",
    "    personal_p = pp.TS_personal_params()\n",
    "    #global_p =gtp.TS_global_params(10,context_dimension)\n",
    "    \n",
    "    global_p.kdim = 11\n",
    "    global_p.baseline_indices = [0,1,2,3,4,5,6]\n",
    "    global_p.psi_indices = [4,6]\n",
    "    global_p.user_id_index = 7\n",
    "    global_p.user_day_index =8\n",
    "    \n",
    "    global_p.baseline_features = ['location','weather']\n",
    "    global_p.psi_features = ['location']\n",
    "    \n",
    "    #print(type(personal_p))\n",
    "    \n",
    "    for person in experiment.population.keys():\n",
    "        experiment.population[person].root = '../../Downloads/distributions/'\n",
    "        initial_context = [0 for i in range(global_p.theta_dim)]\n",
    "        personal_p.mus0[person]= global_p.get_mu0(initial_context)\n",
    "        personal_p.mus1[person]= global_p.get_mu1(initial_context)\n",
    "        personal_p.mus2[person]= global_p.get_mu2(initial_context)\n",
    "        \n",
    "        personal_p.sigmas0[person]= global_p.get_asigma(len( personal_p.mus0[person]))\n",
    "        personal_p.sigmas1[person]= global_p.get_asigma(len( personal_p.mus1[person]))\n",
    "        personal_p.sigmas2[person]= global_p.get_asigma(len( personal_p.mus2[person]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        personal_p.batch[person]=[[] for i in range(len(experiment.person_to_time[person]))]\n",
    "        personal_p.batch_index[person]=0\n",
    "        \n",
    "        personal_p.etas[person]=eta.eta()\n",
    "        \n",
    "        personal_p.last_update[person]=experiment.person_to_time[person][0]\n",
    "    \n",
    "    global_p.write_directory = '../temp'\n",
    "    return global_p ,personal_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(write_dir,dt):\n",
    "    to_return = {}\n",
    "    for d in [f for f in os.listdir(write_dir) if f!='.DS_Store']:\n",
    "        participant = {}\n",
    "        for f in os.listdir('{}/{}'.format(write_dir,d)):\n",
    "            if f!='.DS_Store':\n",
    "                time = int(f.split('_')[1])\n",
    "                if time <=dt:\n",
    "                    with open('{}/{}/{}'.format(write_dir,d,f),'rb') as f:\n",
    "                        ld = pickle.load(f)\n",
    "                    participant[time]=ld\n",
    "                    \n",
    "        pid = d.split('_')[1]\n",
    "        if len(participant)>0:\n",
    "            to_return[int(pid)]=participant\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redo_simulation(experiment,policy=None,personal_policy_params=None,global_policy_params=None):\n",
    "    \n",
    "    for time in experiment.study_days:\n",
    "        if time==experiment.last_update_day+pd.DateOffset(days=1):\n",
    "            experiment.last_update_day=time\n",
    "            ##reset global parameters\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_kind_of_simulation(experiment,policy=None,personal_policy_params=None,global_policy_params=None):\n",
    "    #write_directory = '../../murphy_lab/lab/pooling/temp'\n",
    "    global_policy_params.last_global_update_time=experiment.study_days[0]\n",
    "    experiment.last_update_day=experiment.study_days[0]\n",
    "    for time in experiment.study_days:\n",
    "            \n",
    "            \n",
    "\n",
    "                        \n",
    "        \n",
    "        \n",
    "            if global_policy_params.decision_times>=200:\n",
    "                    break\n",
    "            #if time> experiment.study_days[0]:\n",
    "                #history  = pb.make_history(experiment)\n",
    "            if time==experiment.last_update_day+pd.DateOffset(days=1):\n",
    "\n",
    "                    experiment.last_update_day=time\n",
    "                    \n",
    "\n",
    "                ##global update\n",
    "                #print(time)\n",
    "                #print(experiment.last_update_day+pd.DateOffset(days=1))\n",
    "                ##am i checking the current time (need to check the \n",
    "                #current time make sure i'm not using all of the history)\n",
    "               \n",
    "                #print(history)\n",
    "                \n",
    "                ##these lines\n",
    "\n",
    "                #print(history[0].shape)\n",
    "                    #make_history_new(write_directory,.6,global_policy_params)\n",
    "               #print(temp_params['cov'].shape)\n",
    "                #print(temp_params)\n",
    "                #print(temp_params['cov'].shape)\n",
    "                #print(type(temp_params['cov']))\n",
    "                \n",
    "                #del temp_params\n",
    "                ##update global params using these temp_params\n",
    "                \n",
    "                \n",
    "                \n",
    "            ##update global context\n",
    "            ##global context shared across all participants\n",
    "            tod = sf.get_time_of_day(time)\n",
    "            dow = sf.get_day_of_week(time)\n",
    "            if time==experiment.study_days[0]:\n",
    "                \n",
    "                weather = sf.get_weather_prior(tod,time.month)\n",
    "            elif time.hour in experiment.weather_update_hours and time.minute==0:\n",
    "                weather = sf.get_next_weather(str(tod),str(time.month),weather)\n",
    "            ##location depends on person \n",
    "            \n",
    "            for person in experiment.dates_to_people[time]:\n",
    "                dt=False\n",
    "                action = 0 \n",
    "                prob=0\n",
    "                #1\n",
    "                ##for every active person update person specific aspects of their context\n",
    "                participant = experiment.population[person]\n",
    "                #update global context variables\n",
    "                participant.set_tod(tod)\n",
    "                participant.set_dow(dow)\n",
    "                participant.set_wea(weather)\n",
    "                \n",
    "                \n",
    "                availability = (uniform() < 0.8)\n",
    "                participant.set_available(availability)\n",
    "                \n",
    "                if time == participant.times[0]:\n",
    "                    #get first location \n",
    "                    location = sf.get_location_prior(str(participant.gid),str(dow),str(tod))\n",
    "                    participant.set_inaction_duration(0)\n",
    "                    participant.set_action_duration(0)\n",
    "                    participant.set_duration(0)\n",
    "                    participant.set_dosage(0)\n",
    "                    #personal_policy_params.etas[participant.pid]\n",
    "                    \n",
    "                    \n",
    "                if time <= participant.times[1]:\n",
    "                    steps_last_time_period = 0  \n",
    "                    \n",
    "                    ##set first pre-treatment, yesterday step count, variation and dosage\n",
    "                else:\n",
    "                    \n",
    "                    if time.hour==0 and time.minute==0:\n",
    "                        participant.current_day_counter=participant.current_day_counter+1\n",
    "                    \n",
    "                    #print(time)\n",
    "                    steps_last_time_period = participant.steps\n",
    "                \n",
    "                 \n",
    "                    #get var id\n",
    "                    \n",
    "                #if time.date() <= participant.times[0].date():\n",
    "                    #steps_yesterday = 0    \n",
    "                #else:\n",
    "                    #steps_yesterday =  participant.find_yesterday_steps(time)\n",
    "                    #steps_yesterday = sf.to_yid(steps_yesterday)\n",
    "                steps_yesterday=0    \n",
    "                if time.hour in experiment.location_update_hours:\n",
    "                    location = sf.get_next_location(participant.gid,dow,tod,participant.get_loc())\n",
    "                \n",
    "                if time.date()>(participant.times[0]+pd.DateOffset(days=1)).date():\n",
    "                  \n",
    "                    if time.hour==0 and time.minute==0:\n",
    "                        variation = 0\n",
    "                        #participant.find_variation(time)\n",
    "                else:\n",
    "                    variation = 1 \n",
    "                \n",
    "                participant.set_loc(location)\n",
    "                ##maybe faster to update instead of query?\n",
    "                #participant.set_last_time_period_steps(steps_last_time_period)\n",
    "                #participant.set_yesterday_steps(steps_yesterday)\n",
    "                #participant.set_variation(variation)\n",
    "                \n",
    "                ##continue\n",
    "                #2\n",
    "                ##for every active person take an action according to current context, policy, and parameters\n",
    "                \n",
    "                \n",
    "                ##for now:\n",
    "                ##eval with empty array \n",
    "                if time in participant.decision_times:\n",
    "                                        #print(personal_policy_params.batch_index[participant.pid])\n",
    "                    \n",
    "                    \n",
    "                    ##if we have made no global updates\n",
    "\n",
    "                            \n",
    "                    if global_policy_params.decision_times>=100 and time>experiment.study_days[0]+pd.DateOffset(days=1):\n",
    "                        print(global_policy_params.decision_times)\n",
    "                        #print('getting history')\n",
    "                        global_policy_params.last_global_update_time=time\n",
    "                        history =pb.make_history_new(uniform(),glob,experiment)\n",
    "                        #print(history)\n",
    "                        #print(time)\n",
    "                        temp_params = TS_fancy_pooled.global_updates(history[0],history[1],global_policy_params,train_type = 'empirical_bayes')\n",
    "                        global_policy_params.update_params(temp_params)\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                   \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    dt=True\n",
    "                    action=0\n",
    "                    \n",
    "                    \n",
    "                    if global_policy_params.decision_times>100 and time>experiment.study_days[0]+pd.DateOffset(days=1):\n",
    "                            if   not global_policy_params.updated_cov:\n",
    "                                 global_policy_params.update_cov(global_policy_params.decision_times)   \n",
    "                            #print( global_policy_params.decision_times)\n",
    "                            #print( global_policy_params.last_global_update_time)\n",
    "                            #print(time)\n",
    "                            #print(participant.history)\n",
    "                            history = pb.make_history_new(uniform(),glob,experiment)\n",
    "                    ##update my mu2 and sigma2\n",
    "                            #print(history)\n",
    "                            temp = pb.calculate_posterior(global_policy_params,\\\n",
    "                                                  participant.pid,participant.current_day_counter,\\\n",
    "                                                  history[0], history[1] )\n",
    "                    else:\n",
    "                        temp = [personal_policy_params.mus2[participant.pid],personal_policy_params.sigmas2[participant.pid]]\n",
    "                    mu_beta = temp[0]\n",
    "                    Sigma_beta = temp[1]\n",
    "                    personal_policy_params.update_mus(participant.pid,mu_beta,2)\n",
    "                    personal_policy_params.update_sigmas(participant.pid,Sigma_beta,2)    \n",
    "                    \n",
    "                    \n",
    "                    if policy==None:\n",
    "                        action = sf.get_action(policy)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                    elif policy=='TS':\n",
    "                        #some context slice\n",
    "                            prob = TS.prob_cal_ts([int(tod),int(dow)],participant.dosage,\\\n",
    "                                              personal_policy_params.mus2[participant.pid],personal_policy_params.sigmas2[participant.pid],\\\n",
    "                                                 global_policy_params)\n",
    "                            action = int(uniform() < prob)\n",
    "                            \n",
    "                        \n",
    "                            \n",
    "                    elif policy=='TS_fancy':\n",
    "                        #previous\n",
    "                        #Z, X, mu_beta, Sigma_beta, init,current_eta\n",
    "                        \n",
    "                        ##need to make eta part of the global policy params\n",
    "                        prob = TS_fancy_pooled.prob_cal([location,weather,steps_last_time_period,variation,steps_yesterday],participant.dosage,\\\n",
    "                                              personal_policy_params.mus2[participant.pid],personal_policy_params.sigmas2[participant.pid],\\\n",
    "                                                 global_policy_params,personal_policy_params.etas[participant.pid])\n",
    "                        action = int(uniform() < prob)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                    ##is this the same as in the TS?\n",
    "                    ##don't think so, but for now keep like this\n",
    "                    ##no it isn't, i have to redo this\n",
    "                    \n",
    "\n",
    "                    \n",
    "                    if availability:\n",
    "                    \n",
    "\n",
    "                   \n",
    "                    \n",
    "                    \n",
    "                        participant.update_dosage(action)\n",
    "                    \n",
    "                        context = [action,participant.gid,tod,dow,location,weather,sf.get_pretreatment(participant.steps),\\\n",
    "                              steps_yesterday,variation,sf.dosage_to_dosage_key(participant.dosage)]\n",
    "                    \n",
    "                        participant.steps_last_time_period = participant.steps\n",
    "                        steps = sf.get_steps_action(context)\n",
    "                        participant.steps = steps\n",
    "                    else:\n",
    "                        participant.steps_last_time_period = participant.steps\n",
    "                        steps = sf.get_steps_no_action(participant.gid,tod,dow,location,weather,participant.steps)\n",
    "                        participant.steps = steps\n",
    "                        \n",
    "                \n",
    "                    #my_directory = '{}/participant_{}'.format(global_policy_params.write_directory,participant.pid)\n",
    "                    #if not os.path.exists(my_directory):\n",
    "                        #os.makedirs(my_directory)\n",
    "                   # with open('{}/day_{}'.format(my_directory,global_policy_params.decision_times),'wb') as f:\n",
    "                        #pickle.dump(context_dict,f)\n",
    "                        \n",
    "                        \n",
    "                    global_policy_params.decision_times =   global_policy_params.decision_times+1\n",
    "\n",
    "                    \n",
    "                else:\n",
    "                        participant.steps_last_time_period = participant.steps\n",
    "                        steps = sf.get_steps_no_action(participant.gid,tod,dow,location,weather,participant.steps)\n",
    "                        participant.steps = steps     \n",
    "                \n",
    "                ##history:\n",
    "                context_dict =  {'steps':steps,'action':action,'weather':weather,'location':location,\\\n",
    "                                'ltps':steps_last_time_period,'duration':participant.duration,\\\n",
    "                                'study_day':participant.current_day_counter,'decision_time':dt}\n",
    "                participant.history[time]=context_dict\n",
    "                \n",
    "            #3\n",
    "            ##for every active person generate a step count given current context\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ##update at midnight (here we have ensured that no one has a ) experiment.update_hour\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../temp'\n",
    "for the_file in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, the_file)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = study.study('../../Downloads/distributions/')\n",
    "glob,personal = initialize_policy_params_TS(experiment)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2015-07-22 00:00:00', freq='30T')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.study_days[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky decomposition was not successful. The input might not be valid.\n",
      "\t [[node GPR-9bea2eae-361/likelihood_1/Cholesky (defined at /Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py:64)  = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GPR-9bea2eae-361/likelihood_1/add_3)]]\n",
      "\n",
      "Caused by op 'GPR-9bea2eae-361/likelihood_1/Cholesky', defined at:\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "...\n",
      "  File \"../models/TS_fancy_pooled.py\", line 399, in global_updates\n",
      "    return pb.run(X,y,global_params,gp_train_type=train_type)\n",
      "  File \"../models/pooling_bandits.py\", line 79, in run\n",
      "    m = gpflow.models.GPR(X,y, kern=k)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/core/compilable.py\", line 90, in __init__\n",
      "    self.build()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/core/node.py\", line 156, in build\n",
      "    self._build()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/model.py\", line 79, in _build\n",
      "    likelihood = self._build_likelihood()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/decors.py\", line 49, in name_scope_wrapper\n",
      "    return method(*args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/decors.py\", line 67, in tensor_mode_wrapper\n",
      "    result = method(obj, *args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py\", line 64, in _build_likelihood\n",
      "    L = tf.cholesky(K)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 709, in cholesky\n",
      "    \"Cholesky\", input=input, name=name)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cholesky decomposition was not successful. The input might not be valid.\n",
      "\t [[node GPR-9bea2eae-361/likelihood_1/Cholesky (defined at /Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py:64)  = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GPR-9bea2eae-361/likelihood_1/add_3)]]\n",
      "\n",
      "called\n",
      "True\n",
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky decomposition was not successful. The input might not be valid.\n",
      "\t [[node GPR-2a8a948d-387/likelihood_1/Cholesky (defined at /Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py:64)  = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GPR-2a8a948d-387/likelihood_1/add_3)]]\n",
      "\n",
      "Caused by op 'GPR-2a8a948d-387/likelihood_1/Cholesky', defined at:\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "...\n",
      "  File \"../models/TS_fancy_pooled.py\", line 399, in global_updates\n",
      "    return pb.run(X,y,global_params,gp_train_type=train_type)\n",
      "  File \"../models/pooling_bandits.py\", line 79, in run\n",
      "    m = gpflow.models.GPR(X,y, kern=k)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/core/compilable.py\", line 90, in __init__\n",
      "    self.build()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/core/node.py\", line 156, in build\n",
      "    self._build()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/model.py\", line 79, in _build\n",
      "    likelihood = self._build_likelihood()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/decors.py\", line 49, in name_scope_wrapper\n",
      "    return method(*args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/decors.py\", line 67, in tensor_mode_wrapper\n",
      "    result = method(obj, *args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py\", line 64, in _build_likelihood\n",
      "    L = tf.cholesky(K)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 709, in cholesky\n",
      "    \"Cholesky\", input=input, name=name)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cholesky decomposition was not successful. The input might not be valid.\n",
      "\t [[node GPR-2a8a948d-387/likelihood_1/Cholesky (defined at /Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py:64)  = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GPR-2a8a948d-387/likelihood_1/add_3)]]\n",
      "\n",
      "called\n",
      "True\n",
      "130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky decomposition was not successful. The input might not be valid.\n",
      "\t [[node GPR-5460f0db-517/likelihood_1/Cholesky (defined at /Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py:64)  = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GPR-5460f0db-517/likelihood_1/add_3)]]\n",
      "\n",
      "Caused by op 'GPR-5460f0db-517/likelihood_1/Cholesky', defined at:\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "...\n",
      "  File \"../models/TS_fancy_pooled.py\", line 399, in global_updates\n",
      "    return pb.run(X,y,global_params,gp_train_type=train_type)\n",
      "  File \"../models/pooling_bandits.py\", line 79, in run\n",
      "    m = gpflow.models.GPR(X,y, kern=k)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/core/compilable.py\", line 90, in __init__\n",
      "    self.build()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/core/node.py\", line 156, in build\n",
      "    self._build()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/model.py\", line 79, in _build\n",
      "    likelihood = self._build_likelihood()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/decors.py\", line 49, in name_scope_wrapper\n",
      "    return method(*args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/decors.py\", line 67, in tensor_mode_wrapper\n",
      "    result = method(obj, *args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py\", line 64, in _build_likelihood\n",
      "    L = tf.cholesky(K)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 709, in cholesky\n",
      "    \"Cholesky\", input=input, name=name)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cholesky decomposition was not successful. The input might not be valid.\n",
      "\t [[node GPR-5460f0db-517/likelihood_1/Cholesky (defined at /Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py:64)  = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GPR-5460f0db-517/likelihood_1/add_3)]]\n",
      "\n",
      "called\n",
      "True\n",
      "140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky decomposition was not successful. The input might not be valid.\n",
      "\t [[node GPR-c7d37748-543/likelihood_1/Cholesky (defined at /Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py:64)  = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GPR-c7d37748-543/likelihood_1/add_3)]]\n",
      "\n",
      "Caused by op 'GPR-c7d37748-543/likelihood_1/Cholesky', defined at:\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "...\n",
      "  File \"../models/TS_fancy_pooled.py\", line 399, in global_updates\n",
      "    return pb.run(X,y,global_params,gp_train_type=train_type)\n",
      "  File \"../models/pooling_bandits.py\", line 79, in run\n",
      "    m = gpflow.models.GPR(X,y, kern=k)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/core/compilable.py\", line 90, in __init__\n",
      "    self.build()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/core/node.py\", line 156, in build\n",
      "    self._build()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/model.py\", line 79, in _build\n",
      "    likelihood = self._build_likelihood()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/decors.py\", line 49, in name_scope_wrapper\n",
      "    return method(*args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/decors.py\", line 67, in tensor_mode_wrapper\n",
      "    result = method(obj, *args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py\", line 64, in _build_likelihood\n",
      "    L = tf.cholesky(K)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 709, in cholesky\n",
      "    \"Cholesky\", input=input, name=name)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cholesky decomposition was not successful. The input might not be valid.\n",
      "\t [[node GPR-c7d37748-543/likelihood_1/Cholesky (defined at /Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py:64)  = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GPR-c7d37748-543/likelihood_1/add_3)]]\n",
      "\n",
      "called\n",
      "True\n",
      "142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky decomposition was not successful. The input might not be valid.\n",
      "\t [[node GPR-ec23c3b9-582/likelihood_1/Cholesky (defined at /Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py:64)  = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GPR-ec23c3b9-582/likelihood_1/add_3)]]\n",
      "\n",
      "Caused by op 'GPR-ec23c3b9-582/likelihood_1/Cholesky', defined at:\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "...\n",
      "  File \"../models/TS_fancy_pooled.py\", line 399, in global_updates\n",
      "    return pb.run(X,y,global_params,gp_train_type=train_type)\n",
      "  File \"../models/pooling_bandits.py\", line 79, in run\n",
      "    m = gpflow.models.GPR(X,y, kern=k)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/core/compilable.py\", line 90, in __init__\n",
      "    self.build()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/core/node.py\", line 156, in build\n",
      "    self._build()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/model.py\", line 79, in _build\n",
      "    likelihood = self._build_likelihood()\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/decors.py\", line 49, in name_scope_wrapper\n",
      "    return method(*args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/decors.py\", line 67, in tensor_mode_wrapper\n",
      "    result = method(obj, *args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py\", line 64, in _build_likelihood\n",
      "    L = tf.cholesky(K)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 709, in cholesky\n",
      "    \"Cholesky\", input=input, name=name)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/Users/sabina/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cholesky decomposition was not successful. The input might not be valid.\n",
      "\t [[node GPR-ec23c3b9-582/likelihood_1/Cholesky (defined at /Users/sabina/anaconda3/lib/python3.7/site-packages/gpflow/models/gpr.py:64)  = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](GPR-ec23c3b9-582/likelihood_1/add_3)]]\n",
      "\n",
      "called\n",
      "True\n",
      "145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "True\n",
      "147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hh=new_kind_of_simulation(experiment,'TS_fancy',personal,glob) \n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-244aa7266b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 0.74223465],\n",
       "       [-0.38958099],\n",
       "       [ 5.62654769],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 1.4915105 ],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 2.3843508 ],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 1.19604857],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 3.7946297 ],\n",
       "       [ 0.07431265],\n",
       "       [-0.38958099],\n",
       "       [ 0.15022591],\n",
       "       [-0.38958099],\n",
       "       [ 2.62152467],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 2.35347014],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 0.83856943],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 1.70749537],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.19097463],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 1.83116567],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 1.05936194],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 0.93384008],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.15416103],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 2.10855409],\n",
       "       [ 2.44425486],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [ 0.15351785],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099],\n",
       "       [-0.38958099]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
