{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "#sys.path\n",
    "#sys.path.append('../../../home00/stomkins/pooling_rl/models')\n",
    "#sys.path.append('../../../home00/stomkins/pooling_rl/simulation')\n",
    "import pandas as pd\n",
    "sys.path\n",
    "sys.path.append('../models')\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import run_gpytorchkernel\n",
    "import operator\n",
    "import study\n",
    "import time as time_module\n",
    "import simple_bandits\n",
    "import TS_personal_params_pooled as pp\n",
    "import TS_global_params_pooled as gtp\n",
    "from numpy.random import uniform\n",
    "import run_gpy\n",
    "#sys.path.append('../simulation')\n",
    "import TS_fancy_pooled\n",
    "import TS\n",
    "#import TS_fancy_pooled\n",
    "import eta\n",
    "import pooling_bandits as pb\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import feature_transformations as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_policy_params_TS(experiment,update_period,\\\n",
    "                                standardize=False,baseline_features=None,psi_features=None,\\\n",
    "                                responsivity_keys=None,algo_type=None):\n",
    "    #,'location_1','location_2','location_3'\n",
    "    #'continuous_temp',\n",
    "    global_p =gtp.TS_global_params(21,baseline_features=baseline_features,psi_features=psi_features, responsivity_keys= responsivity_keys)\n",
    "    personal_p = pp.TS_personal_params()\n",
    "    #global_p =gtp.TS_global_params(10,context_dimension)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #global_p.mu_dimension = 64\n",
    "    \n",
    "    global_p.kdim =24\n",
    "    #194\n",
    "    global_p.baseline_indices = [i for i in range(3+ 3*len(baseline_features))]\n",
    "    #[i for i in range(192)]\n",
    "    #[0,1,2,3,4,5,6]\n",
    "    global_p.psi_indices = [0] + [1+baseline_features.index(j) for j in psi_features] \\\n",
    "    + [len(baseline_features)+1] + [(2+len(baseline_features))+baseline_features.index(j) for j in psi_features]\n",
    "    #[0,64]\n",
    "    global_p.user_id_index =0\n",
    "    \n",
    "    global_p.psi_features =psi_features\n",
    "    #[0,64]\n",
    "    \n",
    "    #print(global_p.psi_indices )\n",
    "    \n",
    "    global_p.update_period = update_period\n",
    "    \n",
    "    global_p.standardize = standardize\n",
    "    \n",
    "    \n",
    "    \n",
    "    initial_context = [0 for i in range(global_p.theta_dim)]\n",
    "    \n",
    "    global_p.mus0= global_p.get_mu0(initial_context)\n",
    "    #global_p.get_mu0(initial_context)\n",
    "    global_p.mus1= global_p.get_mu1(global_p.num_baseline_features)\n",
    "    global_p.mus2= global_p.get_mu2(global_p.num_responsivity_features)\n",
    "    #np.array([.120,3.3,-.11])\n",
    "    #global_p.get_mu2(global_p.num_responsivity_features)\n",
    "    \n",
    "    #global_p.sigmas0= global_p.get_asigma(len( personal_p.mus0[person]))\n",
    "    global_p.sigmas1= global_p.get_asigma(global_p.num_baseline_features+1)\n",
    "    global_p.sigmas2= global_p.get_asigma( global_p.num_responsivity_features+1)\n",
    "    \n",
    "    #4.83\n",
    "    global_p.mu2_knot = np.array([0]+[0 for i in range(global_p.num_responsivity_features)])\n",
    "    global_p.mu1_knot = np.zeros(global_p.num_baseline_features+1)\n",
    "    global_p.sigma1_knot = np.eye(global_p.num_baseline_features+1)\n",
    "    global_p.sigma2_knot = np.eye(global_p.num_responsivity_features+1)\n",
    "    #print(type(personal_p))\n",
    "    \n",
    "    for person in experiment.population.keys():\n",
    "        #experiment.population[person].root = '../../regal/murphy_lab/pooling/distributions/'\n",
    "        initial_context = [0 for i in range(global_p.theta_dim)]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if algo_type!='batch':\n",
    "            personal_p.mus0[person]= global_p.get_mu0(initial_context)\n",
    "            personal_p.mus1[person]= global_p.get_mu1(global_p.num_baseline_features)\n",
    "            personal_p.mus2[person]= global_p.get_mu2(global_p.num_responsivity_features)\n",
    "            \n",
    "            personal_p.sigmas0[person]= global_p.get_asigma(len( personal_p.mus0[person]))\n",
    "            personal_p.sigmas1[person]= global_p.get_asigma(global_p.num_baseline_features+1)\n",
    "            personal_p.sigmas2[person]= global_p.get_asigma( global_p.num_responsivity_features+1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        personal_p.batch[person]=[[] for i in range(len(experiment.person_to_time[person]))]\n",
    "        personal_p.batch_index[person]=0\n",
    "        \n",
    "        #personal_p.etas[person]=eta.eta()\n",
    "        \n",
    "        personal_p.last_update[person]=experiment.person_to_time[person][0]\n",
    "\n",
    "\n",
    "    return global_p ,personal_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_reward(beta,states,Z):\n",
    "    if Z is None:\n",
    "        \n",
    "        return np.dot(beta,states)\n",
    "    return np.dot(beta,states)+Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop_size=32\n",
    "#experiment = study.study('../../Downloads/distributions/',pop_size,'_short_unstaggered_6','case_three',sim_number=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = ['tod','dow','pretreatment','location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glob,person = initialize_policy_params_TS(experiment,7,standardize=False,baseline_features=baseline,psi_features=[],responsivity_keys=baseline,algo_type = None)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glob.psi_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_to_save(exp):\n",
    "    to_save  = {}\n",
    "    for pid,pdata in exp.population.items():\n",
    "        for time,context in pdata.history.items():\n",
    "            \n",
    "            key = '{}-{}-{}'.format(pid,time,pdata.gid)\n",
    "            to_save[key]=context\n",
    "    return to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_kind_of_simulation(experiment,policy=None,personal_policy_params=None,global_policy_params=None,generative_functions=None,which_gen=None,feat_trans = None,algo_type = None,case=None,sim_num=None):\n",
    "    #write_directory = '../../murphy_lab/lab/pooling/temp'\n",
    "    experiment.last_update_day=experiment.study_days[0]\n",
    "    tod_check = set([])\n",
    "    \n",
    "    \n",
    "    additives = []\n",
    "    \n",
    "    for time in experiment.study_days:\n",
    "\n",
    "        if time==experiment.last_update_day+pd.DateOffset(days=global_policy_params.update_period):\n",
    "            experiment.last_update_day=time\n",
    "\n",
    "            if global_policy_params.decision_times>2:\n",
    "                global_policy_params.last_global_update_time=time\n",
    "\n",
    "\n",
    "                if algo_type=='batch' or algo_type=='pooling':\n",
    "\n",
    "                    temp_hist = feat_trans.get_history_decision_time_avail(experiment,time)\n",
    "                    temp_hist= feat_trans.history_semi_continuous(temp_hist,global_policy_params)\n",
    "                    context,steps,probs,actions= feat_trans.get_form_TS(temp_hist)\n",
    "                    #print(steps)\n",
    "                    temp_data = feat_trans.get_phi_from_history_lookups(temp_hist)\n",
    "\n",
    "                    steps = feat_trans.get_RT_o(steps,temp_data[0],global_policy_params.mu_theta,global_policy_params.theta_dim)\n",
    "                    #print(steps)\n",
    "                    print('steps {}'.format(steps.std()))\n",
    "                    temp = TS.policy_update_ts_new( context,steps,probs,actions,global_policy_params.noise_term,\\\n",
    "                                                       global_policy_params.mu1_knot,\\\n",
    "                                                       global_policy_params.sigma1_knot,\\\n",
    "                                                       global_policy_params.mu2_knot,\\\n",
    "                                                       global_policy_params.sigma2_knot)\n",
    "\n",
    "                    mu_beta = temp[0]\n",
    "                    Sigma_beta = temp[1]\n",
    "                    #print(mu_beta)\n",
    "                    if algo_type=='batch':\n",
    "                        global_policy_params.update_mus(None,mu_beta,2)\n",
    "                        global_policy_params.update_sigmas(None,Sigma_beta,2)\n",
    "                    else :\n",
    "                        global_posterior = mu_beta\n",
    "                        global_posterior_sigma = Sigma_beta\n",
    "                        try:\n",
    "                            \n",
    "                            #print(baseline_features)\n",
    "                            #print(temp_data[0][:,5])\n",
    "                            temp_params = run_gpytorchkernel.run(temp_data[0], temp_data[1],steps,global_policy_params)\n",
    "                            #print(temp_data[0].shape)\n",
    "                            print(temp_params)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            print('was error')\n",
    "                           # print('global_info',e, time,global_policy_params.decision_times,'error in running gp',file=open('pooling/{}/updates_global_newbigtest_{}_{}_{}six_weeks_only_onoise_errorscurrent.txt'.format(case,len(experiment.population),global_policy_params.update_period,sim_num), 'a'))\n",
    "                            temp_params={'cov':global_policy_params.cov,'noise':global_policy_params.noise_term,'like':-100333,'sigma_u':global_policy_params.sigma_u}\n",
    "                        inv_term = simple_bandits.get_inv_term(temp_params['cov'],temp_data[0].shape[0],temp_params['noise'])\n",
    "                        global_policy_params.update_params(temp_params)\n",
    "                        global_policy_params.inv_term=inv_term\n",
    "                                    #print(temp_params)\n",
    "                        global_policy_params.history = temp_data\n",
    "                        \n",
    "\n",
    "\n",
    "        tod = feat_trans.get_time_of_day(time)\n",
    "        dow = feat_trans.get_day_of_week(time)\n",
    "\n",
    "        if time==experiment.study_days[0]:\n",
    "                        #print('init weather')\n",
    "            weather = feat_trans.get_weather_prior(tod,time.month,seed=experiment.weather_gen)\n",
    "                            #temperature = tf.continuous_temperature(weather)\n",
    "        elif time.hour in experiment.weather_update_hours and time.minute==0:\n",
    "            weather = feat_trans.get_next_weather(str(tod),str(time.month),weather,seed=experiment.weather_gen)\n",
    "\n",
    "        for person in experiment.dates_to_people[time]:\n",
    "            participant = experiment.population[person]\n",
    "            dt=int(time in participant.decision_times)\n",
    "            action = 0\n",
    "            prob=0\n",
    "\n",
    "\n",
    "            if algo_type=='personalized' and dt and time==participant.last_update_day+pd.DateOffset(days=global_policy_params.update_period):\n",
    "                temp_hist = feat_trans.get_history_decision_time_avail_single({participant.pid:participant.history},time)\n",
    "                temp_hist= feat_trans.history_semi_continuous(temp_hist,global_policy_params)\n",
    "                context,steps,probs,actions= feat_trans.get_form_TS(temp_hist)\n",
    "              \n",
    "                temp_data = feat_trans.get_phi_from_history_lookups(temp_hist)\n",
    "                steps = feat_trans.get_RT_o(steps,temp_data[0],global_policy_params.mu_theta,global_policy_params.theta_dim)\n",
    "               \n",
    "                temp = TS.policy_update_ts_new( context,steps,probs,actions,global_policy_params.noise_term,\\\n",
    "                                                           global_policy_params.mu1_knot,\\\n",
    "                                                           global_policy_params.sigma1_knot,\\\n",
    "                                                           global_policy_params.mu2_knot,\\\n",
    "                                                           global_policy_params.sigma2_knot,\n",
    "                                                           #personal_policy_params.mus1[participant.pid],\\\n",
    "                                                           #personal_policy_params.sigmas1[participant.pid],\\\n",
    "                                                           #personal_policy_params.mus2[participant.pid],\\\n",
    "                                                           #personal_policy_params.sigmas2[participant.pid],\n",
    "                                                           \n",
    "                                                           )\n",
    "                mu_beta = temp[0]\n",
    "                Sigma_beta = temp[1]\n",
    "                personal_policy_params.update_mus(participant.pid,mu_beta,2)\n",
    "                personal_policy_params.update_sigmas(participant.pid,Sigma_beta,2)\n",
    "                participant.last_update_day=time\n",
    "            elif algo_type=='pooling'  and global_policy_params.decision_times>2 and global_policy_params.history!=None and  time==participant.last_update_day+pd.DateOffset(days=global_policy_params.update_period):\n",
    "                history = global_policy_params.history\n",
    "                temp = simple_bandits.calculate_posterior_faster(global_policy_params,\\\n",
    "                                                         participant.pid,participant.current_day_counter,\\\n",
    "                                                         history[0], history[1],history[2] )\n",
    "            \n",
    "                                                         #global_posterior = mu_beta\n",
    "                                                         #global_posterior_sigma = Sigma_beta\n",
    "                personal_policy_params.update_mus(participant.pid,mu_beta,2)\n",
    "                personal_policy_params.update_sigmas(participant.pid,Sigma_beta,2)\n",
    "                participant.last_update_day=time\n",
    "            participant.set_tod(tod)\n",
    "            participant.set_dow(dow)\n",
    "\n",
    "            availability = (participant.rando_gen.uniform() < 0.8)\n",
    "    \n",
    "            participant.set_available(availability)\n",
    "            if time == participant.times[0]:\n",
    "                location = feat_trans.get_location_prior(str(participant.gid),str(tod),str(dow),seed = participant.rando_gen)\n",
    "            elif time.hour in experiment.location_update_hours and time.minute==0 :\n",
    "                location = feat_trans.get_next_location(participant.gid,tod,dow,participant.get_loc(),seed =participant.rando_gen)\n",
    "\n",
    "            participant.set_loc(location)\n",
    "\n",
    "            if time <= participant.times[0]:\n",
    "                        steps_last_time_period = 0\n",
    "            else:\n",
    "                if time.hour==0 and time.minute==0:\n",
    "                    participant.current_day_counter=participant.current_day_counter+1\n",
    "\n",
    "                steps_last_time_period = participant.steps\n",
    "\n",
    "            prob = .6\n",
    "            add=None\n",
    "            optimal_action = -1\n",
    "            optimal_reward = -100\n",
    "            if dt:\n",
    "                if policy=='TS':\n",
    "                    pretreatment = feat_trans.get_pretreatment(steps_last_time_period)\n",
    "                    z = [1]\n",
    "\n",
    "                    if 'tod' in global_policy_params.baseline_features:\n",
    "                        z.append(tod)\n",
    "                    if 'dow' in global_policy_params.baseline_features:\n",
    "                        z.append(dow)\n",
    "                    if 'pretreatment' in global_policy_params.baseline_features:\n",
    "                        z.append(pretreatment)\n",
    "                    if 'location' in global_policy_params.baseline_features:\n",
    "                        z.append(location)\n",
    "\n",
    "                    if algo_type=='batch':\n",
    "                        prob = TS.prob_cal_ts(z,0,global_policy_params.mus2,global_policy_params.sigmas2,global_policy_params,seed = experiment.algo_rando_gen)\n",
    "                    elif algo_type=='personalized':\n",
    "                        prob = TS.prob_cal_ts(z,0,personal_policy_params.mus2[participant.pid],personal_policy_params.sigmas2[participant.pid],global_policy_params,seed=experiment.algo_rando_gen)\n",
    "                    elif algo_type=='pooling':\n",
    "                        prob = TS.prob_cal_ts(z,0,personal_policy_params.mus2[participant.pid],personal_policy_params.sigmas2[participant.pid],global_policy_params,seed=experiment.algo_rando_gen)\n",
    "                 \n",
    "                    action = int(experiment.algo_rando_gen.uniform() < prob)\n",
    "                    if availability:\n",
    "                        context = [action,participant.gid,tod,dow,weather,pretreatment,location,\\\n",
    "                                       0,0,0]\n",
    "                        steps = feat_trans.get_steps_action(context,seed = participant.rando_gen)\n",
    "                        add = action*(feat_trans.get_add_no_action(z,experiment.beta,participant.Z))\n",
    "                        participant.steps = steps+add\n",
    "                        optimal_reward = get_optimal_reward(experiment.beta,z,participant.Z)\n",
    "                        optimal_action = int(optimal_reward>=0)\n",
    "                    else:\n",
    "                        steps = feat_trans.get_steps_no_action(participant.gid,tod,dow,location,\\\n",
    "                        pretreatment,weather,seed = participant.rando_gen)\n",
    "                        participant.steps = steps\n",
    "\n",
    "                    global_policy_params.decision_times =   global_policy_params.decision_times+1\n",
    "                else:\n",
    "                        steps = feat_trans.get_steps_no_action(participant.gid,tod,dow,location,\\\n",
    "                                                               pretreatment,weather,seed = participant.rando_gen)\n",
    "                        participant.steps = steps\n",
    "                context_dict =  {'steps':participant.steps,'add':add,'action':action,'location':location,'location_1':int(location==1),\\\n",
    "'ltps':steps_last_time_period,'location_2':int(location==2),'location_3':int(location==3),\\\n",
    "    'study_day':participant.current_day_counter,\\\n",
    "        'decision_time':dt,\\\n",
    "            'time':time,'avail':availability,'prob':prob,\\\n",
    "                'dow':dow,'tod':tod,'weather':weather,\\\n",
    "                    'pretreatment':feat_trans.get_pretreatment(steps_last_time_period),\\\n",
    "                        'optimal_reward':optimal_reward,'optimal_action':optimal_action,\\\n",
    "                            'mu2':global_policy_params.mus2,'gid':participant.gid}\n",
    "\n",
    "                participant.history[time]=context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regret(experiment):\n",
    "    optimal_actions ={}\n",
    "    rewards = {}\n",
    "    actions = {}\n",
    "    for pid,person in experiment.population.items():\n",
    "        for time,data in person.history.items():\n",
    "            if data['decision_time'] and data['avail']:\n",
    "                key = time\n",
    "                if key not in optimal_actions:\n",
    "                    optimal_actions[key]=[]\n",
    "                if key not in rewards:\n",
    "                    rewards[key]=[]\n",
    "                if key not in actions:\n",
    "                    actions[key]=[]\n",
    "                if data['optimal_action']!=-1:\n",
    "                    optimal_actions[key].append(int(data['action']==data['optimal_action']))\n",
    "                    regret = int(data['action']!=data['optimal_action'])*(abs(data['optimal_reward']))\n",
    "                    rewards[key].append(regret)\n",
    "                    actions[key].append(data['action'])\n",
    "    return optimal_actions,rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_to_groupids(exp):\n",
    "    to_save  = {}\n",
    "    for pid,pdata in exp.population.items():\n",
    "        gid  = pdata.gid\n",
    "        key = 'participant-{}'.format(pid)\n",
    "        to_save[key]=gid\n",
    "    return to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_many(algo_type,cases,sim_start,sim_end,update_time,dist_root,write_directory):\n",
    "    for case in cases:\n",
    "        #,'case_two','case_three'\n",
    "        #case = 'case_one'\n",
    "        \n",
    "        \n",
    "        baseline = ['tod','dow','pretreatment','location']\n",
    "        \n",
    "        \n",
    "        \n",
    "        for u in [update_time]:\n",
    "            \n",
    "            all_actions = {}\n",
    "            all_rewards = {}\n",
    "            #'../../Downloads/distributions/'\n",
    "            feat_trans = ft.feature_transformation(dist_root)\n",
    "            \n",
    "            for sim in range(sim_start,sim_end):\n",
    "                pop_size=32\n",
    "                experiment = study.study(dist_root,pop_size,'_short_unstaggered_6',which_gen=case,sim_number=sim)\n",
    "                experiment.update_beta(set(baseline))\n",
    "                #print('beta')\n",
    "                #print(experiment.beta)\n",
    "                glob,personal = initialize_policy_params_TS(experiment,7,standardize=False,baseline_features=baseline,psi_features=[],responsivity_keys=baseline,algo_type =algo_type)\n",
    "                #print(glob.rho_term)\n",
    "                #glob.noise_term  =1.3\n",
    "                hist = new_kind_of_simulation(experiment,'TS',personal,glob,feat_trans=feat_trans,algo_type=algo_type,case=case,sim_num=sim)\n",
    "                to_save = make_to_save(experiment)\n",
    "                actions,rewards = get_regret(experiment)\n",
    "                gids = make_to_groupids(experiment)\n",
    "                    #for i,a in actions.items():\n",
    "                    #if i not in all_actions:\n",
    "                    #all_actions[i]=a\n",
    "                    #else:\n",
    "                    #all_actions[i].extend(a)\n",
    "                    #for i,a in rewards.items():\n",
    "                    # if i not in all_rewards:\n",
    "                    #all_rewards[i]=a\n",
    "                    #else:\n",
    "                    #all_rewards[i].extend(a)\n",
    "            \n",
    "                #return experiment,personal\n",
    "                filename = '{}{}/population_size_{}_update_days_{}_{}_static_sim_{}_alltests.pkl'.format('{}{}/'.format(write_directory,algo_type),case,pop_size,u,'short',sim)\n",
    "                with open(filename,'wb') as f:\n",
    "                    pickle.dump({'gids':gids,'regrets':rewards,'actions':actions,'history':to_save},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps 1.3210221737273073\n",
      "Iter 1/10 - Loss: 1.634\n",
      "Iter 2/10 - Loss: 1.637\n",
      "Iter 3/10 - Loss: 1.638\n",
      "Iter 4/10 - Loss: 1.632\n",
      "Iter 5/10 - Loss: 1.628\n",
      "Iter 6/10 - Loss: 1.627\n",
      "Iter 7/10 - Loss: 1.624\n",
      "Iter 8/10 - Loss: 1.622\n",
      "Iter 9/10 - Loss: 1.622\n",
      "Iter 10/10 - Loss: 1.623\n",
      "{'sigma_u': array([[ 0.02709032, -0.10245742],\n",
      "       [-0.10245742,  0.36270294]]), 'cov': array([[1.5153086, 1.5153086, 1.5153086, ..., 1.       , 1.       ,\n",
      "        1.       ],\n",
      "       [1.5153086, 1.5153086, 1.5153086, ..., 1.       , 1.       ,\n",
      "        1.       ],\n",
      "       [1.5153086, 1.5153086, 3.0153086, ..., 1.       , 2.       ,\n",
      "        2.       ],\n",
      "       ...,\n",
      "       [1.       , 1.       , 1.       , ..., 3.0153086, 3.0153086,\n",
      "        3.0153086],\n",
      "       [1.       , 1.       , 2.       , ..., 3.0153086, 6.0153084,\n",
      "        6.0153084],\n",
      "       [1.       , 1.       , 2.       , ..., 3.0153086, 6.0153084,\n",
      "        6.0153084]], dtype=float32), 'noise': 1.4384609460830688, 'like': 0}\n",
      "steps 1.336886180263299\n",
      "Iter 1/10 - Loss: 1.623\n",
      "Iter 2/10 - Loss: 1.619\n",
      "Iter 3/10 - Loss: 1.619\n",
      "Iter 4/10 - Loss: 1.618\n",
      "Iter 5/10 - Loss: 1.617\n",
      "Iter 6/10 - Loss: 1.618\n",
      "Iter 7/10 - Loss: 1.617\n",
      "Iter 8/10 - Loss: 1.616\n",
      "Iter 9/10 - Loss: 1.614\n",
      "Iter 10/10 - Loss: 1.613\n",
      "{'sigma_u': array([[ 0.0652772 , -0.15397827],\n",
      "       [-0.15397827,  0.49599978]]), 'cov': array([[1.5352988, 1.5352988, 1.5352988, ..., 1.5      , 1.5      ,\n",
      "        1.       ],\n",
      "       [1.5352988, 1.5352988, 1.5352988, ..., 1.5      , 1.5      ,\n",
      "        1.       ],\n",
      "       [1.5352988, 1.5352988, 3.0352988, ..., 3.       , 3.       ,\n",
      "        2.       ],\n",
      "       ...,\n",
      "       [1.5      , 1.5      , 3.       , ..., 6.1200466, 6.2998257,\n",
      "        4.4777255],\n",
      "       [1.5      , 1.5      , 3.       , ..., 6.2998257, 8.536351 ,\n",
      "        5.499826 ],\n",
      "       [1.       , 1.       , 2.       , ..., 4.4777255, 5.499826 ,\n",
      "        6.8354044]], dtype=float32), 'noise': 1.4436365365982056, 'like': 0}\n",
      "steps 1.3496016743090566\n",
      "Iter 1/10 - Loss: 1.621\n",
      "Iter 2/10 - Loss: 1.619\n",
      "Iter 3/10 - Loss: 1.617\n",
      "Iter 4/10 - Loss: 1.617\n",
      "Iter 5/10 - Loss: 1.613\n",
      "Iter 6/10 - Loss: 1.613\n",
      "Iter 7/10 - Loss: 1.614\n",
      "Iter 8/10 - Loss: 1.613\n",
      "Iter 9/10 - Loss: 1.615\n",
      "Iter 10/10 - Loss: 1.616\n",
      "{'sigma_u': array([[ 0.05125188, -0.19187964],\n",
      "       [-0.19187964,  0.83131945]]), 'cov': array([[1.5672021, 1.5672021, 1.5672021, ..., 1.5      , 1.5      ,\n",
      "        1.5      ],\n",
      "       [1.5672021, 1.5672021, 1.5672021, ..., 1.5      , 1.5      ,\n",
      "        1.5      ],\n",
      "       [1.5672021, 1.5672021, 3.067202 , ..., 3.       , 1.5      ,\n",
      "        3.       ],\n",
      "       ...,\n",
      "       [1.5      , 1.5      , 3.       , ..., 8.676289 , 6.969049 ,\n",
      "        6.568586 ],\n",
      "       [1.5      , 1.5      , 1.5      , ..., 6.969049 , 6.942603 ,\n",
      "        4.965992 ],\n",
      "       [1.5      , 1.5      , 3.       , ..., 6.568586 , 4.965992 ,\n",
      "        6.3365803]], dtype=float32), 'noise': 1.4239131212234497, 'like': 0}\n",
      "steps 1.3512155781829476\n",
      "Iter 1/10 - Loss: 1.619\n",
      "Iter 2/10 - Loss: 1.619\n",
      "Iter 3/10 - Loss: 1.615\n",
      "Iter 4/10 - Loss: 1.615\n",
      "Iter 5/10 - Loss: 1.613\n",
      "Iter 6/10 - Loss: 1.614\n",
      "Iter 7/10 - Loss: 1.612\n",
      "Iter 8/10 - Loss: 1.613\n",
      "Iter 9/10 - Loss: 1.613\n",
      "Iter 10/10 - Loss: 1.615\n",
      "{'sigma_u': array([[ 0.02015884, -0.12084421],\n",
      "       [-0.12084421,  0.78068608]]), 'cov': array([[1.5944861, 1.5944861, 1.5944861, ..., 1.5      , 1.5      ,\n",
      "        1.5      ],\n",
      "       [1.5944861, 1.5944861, 1.5944861, ..., 1.5      , 1.5      ,\n",
      "        1.5      ],\n",
      "       [1.5944861, 1.5944861, 3.0944862, ..., 3.       , 3.       ,\n",
      "        3.       ],\n",
      "       ...,\n",
      "       [1.5      , 1.5      , 3.       , ..., 6.1051183, 4.71152  ,\n",
      "        4.71152  ],\n",
      "       [1.5      , 1.5      , 3.       , ..., 4.71152  , 5.3664474,\n",
      "        5.3664474],\n",
      "       [1.5      , 1.5      , 3.       , ..., 4.71152  , 5.3664474,\n",
      "        5.3664474]], dtype=float32), 'noise': 1.44355046749115, 'like': 0}\n",
      "steps 1.3458159573136954\n",
      "Iter 1/10 - Loss: 1.608\n",
      "Iter 2/10 - Loss: 1.610\n",
      "Iter 3/10 - Loss: 1.608\n",
      "Iter 4/10 - Loss: 1.607\n",
      "Iter 5/10 - Loss: 1.605\n",
      "Iter 6/10 - Loss: 1.605\n",
      "Iter 7/10 - Loss: 1.604\n",
      "Iter 8/10 - Loss: 1.603\n",
      "Iter 9/10 - Loss: 1.604\n",
      "Iter 10/10 - Loss: 1.603\n",
      "{'sigma_u': array([[ 0.02382431, -0.14636959],\n",
      "       [-0.14636959,  0.78524476]]), 'cov': array([[1.5737659, 1.5737659, 1.5737659, ..., 1.5      , 1.5      ,\n",
      "        1.5      ],\n",
      "       [1.5737659, 1.5737659, 1.5737659, ..., 1.5      , 1.5      ,\n",
      "        1.5      ],\n",
      "       [1.5737659, 1.5737659, 3.073766 , ..., 1.5      , 3.       ,\n",
      "        3.       ],\n",
      "       ...,\n",
      "       [1.5      , 1.5      , 1.5      , ..., 5.3321896, 3.3462856,\n",
      "        3.3462856],\n",
      "       [1.5      , 1.5      , 3.       , ..., 3.3462856, 6.254494 ,\n",
      "        6.254494 ],\n",
      "       [1.5      , 1.5      , 3.       , ..., 3.3462856, 6.254494 ,\n",
      "        6.254494 ]], dtype=float32), 'noise': 1.400783658027649, 'like': 0}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../Downloads/pooling_results/pooling/case_two/population_size_32_update_days_7_short_static_sim_0_alltests.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-15cd3239bab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pooling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'case_two'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'../../Downloads/distributions/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'../../Downloads/pooling_results/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-3f29bb48ae84>\u001b[0m in \u001b[0;36mrun_many\u001b[0;34m(algo_type, cases, sim_start, sim_end, update_time, dist_root, write_directory)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m#return experiment,personal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}{}/population_size_{}_update_days_{}_{}_static_sim_{}_alltests.pkl'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}{}/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malgo_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpop_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'short'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'gids'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'regrets'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'actions'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'history'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mto_save\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Downloads/pooling_results/pooling/case_two/population_size_32_update_days_7_short_static_sim_0_alltests.pkl'"
     ]
    }
   ],
   "source": [
    "e,p = run_many('pooling',['case_two'],0,1,7,'../../Downloads/distributions/','../../Downloads/pooling_results/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isreal(np.array([[-4.47531231e-03+0.j        , -2.61702768e-18-0.04273931j],\n",
    "       [-2.61702768e-18-0.04273931j,  6.91121340e-01+0.j        ]])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps 1.3331979996275174\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "Iter 1/10 - Loss: 1.631\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "Iter 2/10 - Loss: 1.632\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "Iter 3/10 - Loss: 1.631\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "Iter 4/10 - Loss: 1.622\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "Iter 5/10 - Loss: 1.617\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "Iter 6/10 - Loss: 1.615\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "Iter 7/10 - Loss: 1.611\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "Iter 8/10 - Loss: 1.609\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "Iter 9/10 - Loss: 1.609\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "Iter 10/10 - Loss: 1.611\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000]])\n",
      "{'sigma_u': array([[ 0.02806416, -0.10441858],\n",
      "       [-0.10441858,  0.36308047]]), 'cov': array([[1.5144157, 1.5144157, 1.5144157, ..., 1.       , 1.       ,\n",
      "        1.       ],\n",
      "       [1.5144157, 1.5144157, 1.5144157, ..., 1.       , 1.       ,\n",
      "        1.       ],\n",
      "       [1.5144157, 1.5144157, 3.0144157, ..., 1.       , 2.       ,\n",
      "        2.       ],\n",
      "       ...,\n",
      "       [1.       , 1.       , 1.       , ..., 3.0144157, 3.0144157,\n",
      "        3.0144157],\n",
      "       [1.       , 1.       , 2.       , ..., 3.0144157, 6.0144157,\n",
      "        6.0144157],\n",
      "       [1.       , 1.       , 2.       , ..., 3.0144157, 6.0144157,\n",
      "        6.0144157]], dtype=float32), 'noise': tensor([[1.4482]], grad_fn=<AddBackward0>), 'like': 0}\n",
      "steps 1.3169956049428557\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "Iter 1/10 - Loss: 1.613\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2/10 - Loss: 1.607\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "Iter 3/10 - Loss: 1.605\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "Iter 4/10 - Loss: 1.601\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "Iter 5/10 - Loss: 1.598\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "Iter 6/10 - Loss: 1.596\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        [1.0000, 0.5000],\n",
      "        ...,\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000],\n",
      "        [1.0000, 0.8000]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-850409a05047>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pooling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'case_one'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'../../Downloads/distributions/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'../../Downloads/pooling_results/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-3f29bb48ae84>\u001b[0m in \u001b[0;36mrun_many\u001b[0;34m(algo_type, cases, sim_start, sim_end, update_time, dist_root, write_directory)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;31m#print(glob.rho_term)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;31m#glob.noise_term  =1.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_kind_of_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'TS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpersonal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeat_trans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_trans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malgo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malgo_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mto_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_to_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_regret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d8b5af7842a4>\u001b[0m in \u001b[0;36mnew_kind_of_simulation\u001b[0;34m(experiment, policy, personal_policy_params, global_policy_params, generative_functions, which_gen, feat_trans, algo_type, case, sim_num)\u001b[0m\n\u001b[1;32m     46\u001b[0m                             \u001b[0;31m#print(baseline_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                             \u001b[0;31m#print(temp_data[0][:,5])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                             \u001b[0mtemp_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_gpytorchkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_policy_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                             \u001b[0;31m#print(temp_data[0].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pooling_rl/models/run_gpytorchkernel.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(X, users, y, global_params)\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m#print(type(output))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iter %d/%d - Loss: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output, target, *params)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Add terms for SGPR / when inducing points are learned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# Get log determininat and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1021\u001b[0m                 )\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minv_quad_rhs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mrepresentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1245\u001b[0m                 \u001b[0mrepresentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"representation\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Is it a LazyTensor?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m                 \u001b[0mrepresentation\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Representation of a LazyTensor should consist only of Tensors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mrepresentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcache_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0madd_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             res = self.kernel(\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             )\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_active_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x1, x2, diag, batch_dims, **params)\u001b[0m\n\u001b[1;32m    507\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLazyEvaluatedKernelTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0;31m# Now we'll make sure that the shape we're getting makes sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pooling_rl/models/run_gpytorchkernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, batch_dims, **params)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m#print(random_effects.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#print(self.user_mat.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_effects\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m#print(final.evaluate())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1713\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__radd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "e,p = run_many('pooling',['case_one'],0,1,7,'../../Downloads/distributions/','../../Downloads/pooling_results/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tone = torch.tensor([[2,3,4,5,6,1],[2,3,3,5,6,1]])\n",
    "ttwo = torch.tensor([[0,0,0,0,0,3],[1,0,0,0,0,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((tone[:,0],tone[:,1]),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.stack([tone[:,i] for  i in [0,1]],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
